{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import importlib\n",
    "import framework\n",
    "importlib.reload(framework)\n",
    "import test_classifier\n",
    "importlib.reload(test_classifier)\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "from framework import Usecase, DataCuration, FeatureEngineering, ModelEvaluator\n",
    "import pandas as pd\n",
    "import random\n",
    "# Define some constants and configurations\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "ACCESS_TOKEN = 'WUpGevbWC9lsnTW8quNUtmWRdAEM89'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the usecase details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "USECASE = 'ner'\n",
    "USECASE_CONFIG = {\n",
    "    'dataset': 'w2',\n",
    "    'num_labels': 3,\n",
    "    'labels_dict': {'person' : 0, 'org' : 1, 'none': 2},\n",
    "     'cat_dict': {0: 'person', 1: 'org', 2: 'none'}\n",
    "}\n",
    "\n",
    "usecase = Usecase(USECASE)\n",
    "usecase.setConfig(USECASE_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths for datasets and goldens (local or ib, both work).\n",
    "Specify configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Loading dataset from /Users/ahsaasbajaj/Documents/Data/w2-instabase/flow/s2_map_records\nINFO:root:Loading goldens from /Users/ahsaasbajaj/Documents/Data/w2-instabase/golden/goldens.csv\nTotal files Goldens:  (154, 25)\nTotal files found in the source (142, 25)\n"
    }
   ],
   "source": [
    "DATAS = {\n",
    "    ('ner', 'w2') : '/Users/ahsaasbajaj/Documents/Data/w2-instabase/flow/s2_map_records'\n",
    "}\n",
    "\n",
    "GOLDENS = {\n",
    "  ('ner', 'w2') : '/Users/ahsaasbajaj/Documents/Data/w2-instabase/golden/goldens.csv'\n",
    "}\n",
    "\n",
    "DATASET = USECASE_CONFIG['dataset']\n",
    "DATA = DATAS[(USECASE, DATASET)]\n",
    "GOLDEN = GOLDENS[(USECASE, DATASET)]\n",
    "\n",
    "GOLDEN_CONFIG = {\n",
    "    'is_local': True,\n",
    "    'index_field_name':'filename',\n",
    "    'file_type': 'csv',\n",
    "    'skip_first_row': True,\n",
    "    'identifier': 'file'\n",
    "}\n",
    "DATASET_CONFIG = {\n",
    "    'is_local': True, \n",
    "    'file_type': 'ibocr',\n",
    "    'identifier': lambda path: os.path.basename(path).split('.ibocr')[0],\n",
    "    'convert2txt': False\n",
    "}\n",
    "\n",
    "w2 = DataCuration(ACCESS_TOKEN, DATA, DATASET_CONFIG, GOLDEN, GOLDEN_CONFIG)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Generating candidates for 142 files\nFor X_DIST_THRESHOLD configuraion: 100\ntotal files: 142\nperson names found in candidates: 131\norg names found in candidates: 79\n\n"
    }
   ],
   "source": [
    "PROCESSING_CONFIG = {\n",
    "    'X_DIST_THRESHOLD': 100\n",
    "}\n",
    "CANDIDATES_FIELDS = {\n",
    "    'person':'employee_name',\n",
    "    'org':'employer_name'\n",
    "}\n",
    "w2.processIBOCR2candidatePhrases(DATASET_CONFIG, PROCESSING_CONFIG)\n",
    "w2.compare_candidates_and_goldens(PROCESSING_CONFIG, CANDIDATES_FIELDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test data from goldens (from actual persons and company names) or from ibocr (using candidate phrases generated by processIBOCR2candidatePhrases())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fe = FeatureEngineering(usecase, w2, CANDIDATES_FIELDS)\n",
    "test_data_from_goldens = fe.generate_test_samples_from_goldens() # single dataframe\n",
    "test_data_from_candidates = fe.generate_test_samples_from_candidates() # dict{'filename' : dataframe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_TRAIN_DATA = 'w2'     # options for NER: (w2 or public)\n",
    "\n",
    "MODELS = {\n",
    "    ('ner', 'w2') : '/Users/ahsaasbajaj/Documents/Code/ner-hf/sequence-classification/w2/no-address/5/model.pt',\n",
    "    ('ner', 'public') : '/Users/ahsaasbajaj/Documents/Code/ner-hf/sequence-classification/public/no-address/200/model.pt'\n",
    "}\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'model_file_or_path' : MODELS[(USECASE, MODEL_TRAIN_DATA)],\n",
    "    'num_labels': USECASE_CONFIG['num_labels'],\n",
    "}\n",
    "\n",
    "EVAL_CONFIG = {\n",
    "    'gpu': False,\n",
    "    'use_goldens': False # True if test_data generated using generate_test_samples_from_goldens(), else False\n",
    "}\n",
    "test_data = test_data_from_candidates\n",
    "\n",
    "# testing -- include as module alongwith support with sampling from df\n",
    "test_data = dict(random.sample(test_data.items(), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Device:  cpu\nINFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json from cache at /Users/ahsaasbajaj/.cache/torch/transformers/90deb4d9dd705272dc4b3db1364d759d551d72a9f70a91f60e3a1f5e278b985d.9019d8d0ae95e32b896211ae7ae130d7c36bb19ccf35c90a9e51923309458f70\nINFO:transformers.configuration_utils:Model config BertConfig {\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"type_vocab_size\": 2,\n  \"vocab_size\": 28996\n}\n\nINFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-large-cased-pytorch_model.bin from cache at /Users/ahsaasbajaj/.cache/torch/transformers/5f91c3ab24cfb315cf0be4174a25619f6087eb555acc8ae3a82edfff7f705138.b5f1c2070e0a0c189ca3b08270b0cb5bd0635b7319e74e93bd0dc26689953c27\nINFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /Users/ahsaasbajaj/.cache/torch/transformers/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\nFine-tuned model loaded with labels =  3\nTokenize the first sentence: ['[CLS]', 'late', \"'\", 's', '##s']\nLabels length: 19\nTokenized texts Length:  19\nDevice:  cpu\nINFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json from cache at /Users/ahsaasbajaj/.cache/torch/transformers/90deb4d9dd705272dc4b3db1364d759d551d72a9f70a91f60e3a1f5e278b985d.9019d8d0ae95e32b896211ae7ae130d7c36bb19ccf35c90a9e51923309458f70\nINFO:transformers.configuration_utils:Model config BertConfig {\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"type_vocab_size\": 2,\n  \"vocab_size\": 28996\n}\n\nINFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-large-cased-pytorch_model.bin from cache at /Users/ahsaasbajaj/.cache/torch/transformers/5f91c3ab24cfb315cf0be4174a25619f6087eb555acc8ae3a82edfff7f705138.b5f1c2070e0a0c189ca3b08270b0cb5bd0635b7319e74e93bd0dc26689953c27\nINFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /Users/ahsaasbajaj/.cache/torch/transformers/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\nFine-tuned model loaded with labels =  3\nTokenize the first sentence: ['[CLS]', 'notice', 'to', 'employee']\nLabels length: 48\nTokenized texts Length:  48\n2\nFor field person, recall: 1.0000, precision: 0.3750, F1: 0.5455 \nFor field org, recall: 1.0000, precision: 0.5000, F1: 0.6667 \n"
    }
   ],
   "source": [
    "\n",
    "model_evaluator = ModelEvaluator(usecase)\n",
    "model_evaluator.set_config(MODEL_CONFIG, EVAL_CONFIG)\n",
    "\n",
    "# Predictions (on test data generated from goldens)\n",
    "output = model_evaluator.run_evaluation(test_data)\n",
    "\n",
    "# Analyze results generated\n",
    "if EVAL_CONFIG['use_goldens']:\n",
    "    # output is a single df\n",
    "    print('Sample outputs: ', output.head())\n",
    "    model_evaluator.analyze_golden_result(output)\n",
    "else:\n",
    "    print(len(output.keys()))\n",
    "    # output is a dictionary\n",
    "    results = model_evaluator.analyze_overall_result(output, w2.golden, CANDIDATES_FIELDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\n# Print results\\nfor typ in results:\\n    print('Field type: ', typ)\\n        for key in results[typ]:\\n            print('filename: ', key)\\n            print(results[typ][key])\\n\""
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "'''\n",
    "# Print results\n",
    "for typ in results:\n",
    "    print('Field type: ', typ)\n",
    "        for key in results[typ]:\n",
    "            print('filename: ', key)\n",
    "            print(results[typ][key])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REFINER_RESULTS = {\n",
    "    ('ner', 'w2') : '/Users/ahsaasbajaj/Documents/Code/ner-hf/sequence-classification/refiner_results/w2.ibocr',\n",
    "    ('ner', 'resume') : '/Users/ahsaasbajaj/Documents/Code/ner-hf/sequence-classification/refiner_results/resume.ibocr'\n",
    "}\n",
    "\n",
    "REFINER_RESULT_PATH = REFINER_RESULTS[(USECASE, MODEL_TRAIN_DATA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nPerson Name Scores\nFor model names_vontell, recall: 0.7465, precision: 0.4180, F1: 0.5359 \nFor model names_token_matcher, recall: 0.6549, precision: 0.4602, F1: 0.5405 \nFor model names_spacy, recall: 0.0915, precision: 0.0034, F1: 0.0066 \n\nOrg Name Scores\nFor model org_spacy, recall: 0.0775, precision: 0.0012, F1: 0.0023 \n"
    }
   ],
   "source": [
    "model_evaluator = ModelEvaluator(usecase)\n",
    "results = model_evaluator.analyze_refiner_results(REFINER_RESULT_PATH, w2.golden, CANDIDATES_FIELDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\" \\n# Print results\\nfor typ in results:\\n    print('Field type: ', typ)\\n    for model in results[typ]:\\n        print('model type: ', model)\\n        for key in results[typ][model]:\\n            print('filename: ', key)\\n            print(results[typ][model][key])\\n\""
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "''' \n",
    "# Print results\n",
    "for typ in results:\n",
    "    print('Field type: ', typ)\n",
    "    for model in results[typ]:\n",
    "        print('model type: ', model)\n",
    "        for key in results[typ][model]:\n",
    "            print('filename: ', key)\n",
    "            print(results[typ][model][key])\n",
    "'''            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595217358483",
   "display_name": "Python 3.7.3 64-bit ('3.7.3': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}