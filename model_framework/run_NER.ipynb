{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import logging\n",
    "importlib.reload(logging)\n",
    "import framework\n",
    "importlib.reload(framework)\n",
    "import bert_ner\n",
    "importlib.reload(bert_ner)\n",
    "import infer_bert_classifier\n",
    "importlib.reload(infer_bert_classifier)\n",
    "import bert_utils\n",
    "importlib.reload(bert_utils)\n",
    "import pandas as pd\n",
    "from framework import DataCuration, FeatureEngineering\n",
    "from bert_ner import TaskNER, FeatureEngineeringNER, BERTNER\n",
    "\n",
    "# Define some constants and configurations\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "ACCESS_TOKEN = 'WUpGevbWC9lsnTW8quNUtmWRdAEM89'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the task details. This notebook handles NER (for labeling person and company names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'w2' # supports w2 and resume\n",
    "TASK_CONFIG = {\n",
    "    'task': 'ner',\n",
    "    'num_labels': 3,\n",
    "    'labels_dict': {'person' : 0, 'org' : 1, 'none': 2}\n",
    "}\n",
    "\n",
    "task = TaskNER(TASK_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths for datasets and goldens (local or ib, both work).\n",
    "Specify configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Loading dataset from /Users/ahsaasbajaj/Documents/Data/w2-instabase/flow/s2_map_records\nINFO:root:142 files loaded\nINFO:root:Loading goldens from /Users/ahsaasbajaj/Documents/Data/w2-instabase/golden/goldens.csv\nINFO:root:Total files Goldens: (154, 25)\nINFO:root:Total files found in the source with unique index: (142, 25)\nINFO:root:Processing 142 IBOCR files to txt\n"
    }
   ],
   "source": [
    "W2_DATA = [\n",
    "   '/Users/ahsaasbajaj/Documents/Data/w2-instabase/flow/s2_map_records'\n",
    "]\n",
    "W2_GOLDEN = [\n",
    "   '/Users/ahsaasbajaj/Documents/Data/w2-instabase/golden/goldens.csv'\n",
    "]\n",
    "\n",
    "GOLDEN_CONFIG = {\n",
    "    'path': W2_GOLDEN,\n",
    "    'is_local': True,\n",
    "    'index_field_name':'filename',\n",
    "    'file_type': 'csv',\n",
    "    'identifier': 'file'\n",
    "}\n",
    "DATASET_CONFIG = {\n",
    "    'path': W2_DATA,\n",
    "    'is_local': True, \n",
    "    'file_type': 'ibocr',\n",
    "    'identifier': lambda path: os.path.basename(path).split('.ibocr')[0],\n",
    "    'convert2txt': True\n",
    "}\n",
    "\n",
    "data = DataCuration(ACCESS_TOKEN, DATASET_CONFIG, GOLDEN_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Generating candidates for 142 files\nINFO:root:For X_DIST_THRESHOLD configuraion: 200\nINFO:root:total files: 142\nperson names found in candidates: 130\norg names found in candidates: 69\n\n"
    }
   ],
   "source": [
    "PROCESSING_CONFIG = {\n",
    "    'X_DIST_THRESHOLD': 200\n",
    "}\n",
    "\n",
    "DATA_ARGS = {\n",
    "    'task': task,\n",
    "    'dataset': data,\n",
    "    'candidates_fields': {\n",
    "        'person':'employee_name',\n",
    "        'org':'employer_name'\n",
    "    }\n",
    "}\n",
    "\n",
    "data.generate_candidates_phrases(PROCESSING_CONFIG)\n",
    "data.compare_candidates_and_goldens(DATA_ARGS['candidates_fields'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test data from goldens (from actual persons and company names) or from ibocr (using candidate phrases generated by processIBOCR2candidatePhrases())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fe = FeatureEngineeringNER(DATA_ARGS)\n",
    "test_data_from_goldens = fe.generate_test_samples_from_goldens() # single dataframe\n",
    "test_data_from_candidates = fe.generate_test_samples_from_candidates() # dict{'filename' : dataframe}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading fine-tuned model for inference. These models were separately trained using GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATHS = {\n",
    "    'w2' : '/Users/ahsaasbajaj/Documents/Code/ner-hf/sequence-classification/w2/no-address/5/model.pt', # trained on public w2 from Kaggle\n",
    "    'public': '/Users/ahsaasbajaj/Documents/Code/ner-hf/sequence-classification/public/no-address/200/model.pt' # trained on public names repo\n",
    "}\n",
    "\n",
    "TRAINING_ARGS = {\n",
    "    'model_file_or_path' : MODEL_PATHS['w2'],\n",
    "    'num_labels': TASK_CONFIG['num_labels'],\n",
    "    'gpu': False,\n",
    "}\n",
    "\n",
    "model = BERTNER(DATA_ARGS, TRAINING_ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup model evaluator and evaluate either using test_data generated from goldens (test_data_from_goldens) or all candidate strings (test_data_from_candidates). Below code runs BERT inference and performs extraction, also calculating Recall, Precision, F1 by comparing with goldens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:inferring BERT classifier for file last_year_w2_1494968117938.PDF\nINFO:root:inferring BERT classifier for file last_year_w2_1494968749784.PDF\nINFO:root:For field person, recall: 1.0000, precision: 0.6667, F1: 0.8000 \nINFO:root:For field org, recall: 0.5000, precision: 0.2500, F1: 0.3333 \nNumber of files:  2\n"
    }
   ],
   "source": [
    "# Predictions\n",
    "# output_golden = model.predict(test_data_from_goldens) # single dataframe \n",
    "\n",
    "# print('Sample outputs: ', output_golden.head())\n",
    "# model.analyze_golden_result(output_golden)\n",
    "\n",
    "\n",
    "# Do only for debugging and getting quick results\n",
    "test_data_from_candidates = FeatureEngineering.get_subset_for_debugging(test_data_from_candidates, sample_size=2)\n",
    "\n",
    "output = model.predict(test_data_from_candidates) # output is a dictionary\n",
    "print('Number of files: ', len(output.keys()))\n",
    "results = model.analyze_result(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Field type: person\nINFO:root:filename: last_year_w2_1494968117938.PDF\nINFO:root:{'DARICK J ENDECOTT'}\nINFO:root:filename: last_year_w2_1494968749784.PDF\nINFO:root:{'HEWLETT PACKARD ENTERPRISE', 'PATRICK J WAGNER', 'Local:'}\nINFO:root:Field type: org\nINFO:root:filename: last_year_w2_1494968117938.PDF\nINFO:root:{'SUI/SDI', 'FUSION LED INC'}\nINFO:root:filename: last_year_w2_1494968749784.PDF\nINFO:root:{'COMPANY.', 'COMPANY'}\n"
    }
   ],
   "source": [
    "model.demo(results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596015423953",
   "display_name": "Python 3.7.3 64-bit ('3.7.3': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}