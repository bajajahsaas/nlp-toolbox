{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering\n",
    "- This notebook extracts exact answers to queries from long natural language documents (CARTA Contracts)\n",
    "\n",
    "- This script uses pretrained model (BERT-based question answering) available in huggingface library, which was trained on SQUAD dataset\n",
    "\n",
    "- If supervised training data is available, we can finetune this model using techniques similar to train_NER.ipynb\n",
    "\n",
    "\n",
    "### Example: \n",
    "\n",
    "context = \"New Zealand (Māori: Aotearoa) is a sovereign island country in the southwestern Pacific Ocean. It has a total land area of 268,000 square kilometres (103,500 sq mi), and a population of 4.9 million. New Zealand's capital city is Wellington, and its most populous city is Auckland.\"\n",
    "\n",
    "questions = \"How many people live in New Zealand?\", \"What's the largest city?\"\n",
    "\n",
    "Answers = 4.9 million, Auckland\n",
    "\n",
    "- Online Demo of BERT-based QA model: https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad\n",
    "\n",
    "### Note:\n",
    "- This script is almost same as *run_QA.ipynb*, but here the data path has just one document, and we run just 1 query for faster execution. \n",
    "\n",
    "- Also we use local model files downloaded from above link instead of asking huggingface to download model at runtime\n",
    "\n",
    "Final Intern presentation: https://docs.google.com/presentation/d/10mXA7K5sa_nAkqx2onsIfrH3TPj2Ni4LfCOxDhN5XBI/edit?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import logging\n",
    "import time\n",
    "importlib.reload(logging)\n",
    "import framework\n",
    "importlib.reload(framework)\n",
    "import bert_qa\n",
    "importlib.reload(bert_qa)\n",
    "import infer_bert_qa\n",
    "importlib.reload(infer_bert_qa)\n",
    "import bert_utils\n",
    "importlib.reload(bert_utils)\n",
    "import pandas as pd\n",
    "from framework import DataCuration, FeatureEngineering\n",
    "from bert_qa import TaskQA, FeatureEngineeringQA, BERTQA\n",
    "\n",
    "# Define some constants and configurations\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "ACCESS_TOKEN = 'WUpGevbWC9lsnTW8quNUtmWRdAEM89'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Task\n",
    "- Mention configurations of the task and create a task object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'carta' # supports w2 and resume\n",
    "TASK_CONFIG = {\n",
    "    'task': 'qa'\n",
    "}\n",
    "\n",
    "task = TaskQA(TASK_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate dataset\n",
    "- Specify paths for dataset. Paths can be local or from instabase drives (use *is_local*). \n",
    "- Limit data path to have just one document (for demo purpose of this notebook)\n",
    "- Also specify configurations like extensions, column names to use as index. \n",
    "- Currently supports csv format for goldens, ibocr/ibdoc for dataset. \n",
    "- Use *context2txt* to extract and store raw texts. \n",
    "- This object can be queried using *data.golden* or *data.dataset* or *data.dataset.texts* based on requirement\n",
    "\n",
    "### Files:\n",
    "- Download documents (ibocr files) from https://www.instabase.com/ib_solutions/solutions/fs/Instabase%20Drive/poc/carta/Annotated%20Sample/out/s1_process_files/ and specify local directory path. Use *is_local* as True\n",
    "- Alternatively, specify instabase drive path (/ib_solutions/solutions/fs/Instabase%20Drive/poc/carta/Annotated%20Sample/out/s1_process_files/) and set *is_local* as False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Loading dataset from /Users/ahsaasbajaj/Documents/Data/QA_model/data\nINFO:root:1 files loaded\nINFO:root:Converting IBOCR/IBDOC to raw texts\n"
    }
   ],
   "source": [
    "CARTA_DATA = [\n",
    "   '/Users/ahsaasbajaj/Documents/Data/QA_model/data'\n",
    "]\n",
    "\n",
    "DATASET_CONFIG = {\n",
    "    'path': CARTA_DATA,\n",
    "    'is_local': True, \n",
    "    'file_type': 'ibocr',\n",
    "    'identifier': lambda path: os.path.basename(path).split('.ibocr')[0],\n",
    "    'convert2txt': True\n",
    "}\n",
    "\n",
    "CARTA_GOLDEN = None\n",
    "GOLDEN_CONFIG = None\n",
    "\n",
    "data = DataCuration(ACCESS_TOKEN, DATASET_CONFIG, GOLDEN_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'annotated_AOI_4.pdf': <instabase.ocr.client.libs.ibocr.ParsedIBOCR at 0x156066668>}"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (BERT Inference for question answering)\n",
    "- Specify model type and load fine-tuned model for inference\n",
    "- Specify queries to be inferred\n",
    "- This model uses pretrained BERT QA model which was finetuned on standard datasets\n",
    "\n",
    "### Specify TRAINING_ARGS\n",
    "- Mention the class of model, to be used appropriately by back-end huggingface libraries\n",
    "- Mention the path where outputs to queries are to be written\n",
    "- Also supports the use of GPU for deep learning libraries\n",
    "\n",
    "### Specify query (can be a single string or a list of queries) for question answering\n",
    "\n",
    "\n",
    "### Model Files:\n",
    "Specify bert-large-uncased-whole-word-masking-finetuned-squad in *model_file_or_path* of TRAINING_ARGS for huggingface to automatically downloads checkpoint in runtime\n",
    "\n",
    "Alternatively, follow the steps below:\n",
    "- Download (config.json, modelcard.json, pytorch_model.bin, vocab.txt) files from https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad#list-files\n",
    "- Rename names of downloaded files to the exact names mentioned in link above\n",
    "- Specify the local directory path containing above files in *model_file_or_path* of TRAINING_ARGS\n",
    "\n",
    "#### This block of code gets answer for *query* for document in *CARTA_DATA*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root: Total number of Files: 1\nINFO:root:File name: annotated_AOI_4.pdf\nconvert squad examples to features: 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\nadd example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 2267.19it/s]\nINFO:root:Total time 164.56057405471802 seconds\nWhat are the Preferred stocks? : Series A Preferred Stock and Series A-1 Preferred Stock\n"
    }
   ],
   "source": [
    "query = \"What are the Preferred stocks?\"\n",
    "\n",
    "NUM_FILES = len(data.dataset.keys())\n",
    "stime = time.time()\n",
    "\n",
    "DATA_ARGS = {\n",
    "    'task': task,\n",
    "    'dataset': data\n",
    "}\n",
    "\n",
    "TRAINING_ARGS = {\n",
    "'model_file_or_path': \"/Users/ahsaasbajaj/Documents/Data/QA_model/model\",\n",
    "'gpu': False,\n",
    "'output_dir': '../outputs/bert_qa'\n",
    "}\n",
    "\n",
    "model = BERTQA(DATA_ARGS, TRAINING_ARGS)\n",
    "output = model.predict(query)\n",
    "\n",
    "etime = time.time()\n",
    "logging.info('Total time {} seconds'.format(etime - stime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print filenname, questions and corresponding answers generated by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "filename:  annotated_AOI_4.pdf\nquery:  What are the Preferred stocks?\nanswer:  Series A Preferred Stock and Series A-1 Preferred Stock\n"
    }
   ],
   "source": [
    "output = output.set_index('filename')\n",
    "filenames = output.index.to_list()\n",
    "\n",
    "for filename in filenames:\n",
    "    print(\"filename: \", filename)\n",
    "\n",
    "    for col in output.columns.to_list():\n",
    "        print(\"query: \", col)\n",
    "        answer = output.loc[filename, col]\n",
    "        print(\"answer: \", answer)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597996490146",
   "display_name": "Python 3.7.3 64-bit ('3.7.3': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}