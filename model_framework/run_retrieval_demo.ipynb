{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import logging\n",
    "import time\n",
    "importlib.reload(logging)\n",
    "import framework\n",
    "importlib.reload(framework)\n",
    "import bert_qa\n",
    "importlib.reload(bert_qa)\n",
    "import infer_bert_qa\n",
    "importlib.reload(infer_bert_qa)\n",
    "import bert_utils\n",
    "importlib.reload(bert_utils)\n",
    "import pandas as pd\n",
    "from framework import DataCuration, FeatureEngineering\n",
    "from retrieval import TaskRetrieval, FeatureEngineeringRetrieval, Retrieval\n",
    "\n",
    "# Define some constants and configurations\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "ACCESS_TOKEN = 'WUpGevbWC9lsnTW8quNUtmWRdAEM89'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the task details. This notebook handles Document Retrieval for CARTA dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'carta' # supports w2 and resume\n",
    "TASK_CONFIG = {\n",
    "    'task': 'retrieval'\n",
    "}\n",
    "\n",
    "task = TaskRetrieval(TASK_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths for datasets and goldens (local or ib, both work).\n",
    "Specify configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Loading dataset from /Users/ahsaasbajaj/Documents/Data/QA_model/data\nINFO:root:1 files loaded\nINFO:root:Processing 1 IBOCR files to txt\n"
    }
   ],
   "source": [
    "CARTA_DATA = [\n",
    "    # should contain only a single document, since the huge doc will be split into many segments (each treated as a new doc for retrieval)\n",
    "   '/Users/ahsaasbajaj/Documents/Data/QA_model/data'\n",
    "]\n",
    "\n",
    "DATASET_CONFIG = {\n",
    "    'path': CARTA_DATA,\n",
    "    'is_local': True, \n",
    "    'file_type': 'ibocr',\n",
    "    'identifier': lambda path: os.path.basename(path).split('.ibocr')[0],\n",
    "    'convert2txt': True\n",
    "}\n",
    "\n",
    "CARTA_GOLDEN = None\n",
    "GOLDEN_CONFIG = None\n",
    "\n",
    "data = DataCuration(ACCESS_TOKEN, DATASET_CONFIG, GOLDEN_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'annotated_AOI_4.pdf': <instabase.ocr.client.libs.ibocr.ParsedIBOCR at 0x154905828>}"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "filename to split and query:  annotated_AOI_4.pdf\n"
    }
   ],
   "source": [
    "filename = list(data.dataset.keys())[0]\n",
    "print('filename to split and query: ', filename)\n",
    "\n",
    "query = \"Preferred Stocks\"\n",
    "\n",
    "NUM_FILES = len(data.dataset.keys())\n",
    "stime = time.time()\n",
    "\n",
    "DATA_ARGS = {\n",
    "    'task': task,\n",
    "    'dataset': data\n",
    "}\n",
    "\n",
    "TRAINING_ARGS = {\n",
    "'model_file_or_path': \"BM25Okapi\"\n",
    "}\n",
    "\n",
    "fe = FeatureEngineeringRetrieval(DATA_ARGS)\n",
    "\n",
    "corpus = fe.split_doc(filename=filename, split_size=100)  # list of document segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Total time 0.024983882904052734 seconds\n"
    }
   ],
   "source": [
    "tokenized_corpus = fe.tokenize_corpus(corpus)\n",
    "\n",
    "model = Retrieval(DATA_ARGS, TRAINING_ARGS)\n",
    "model.train(corpus, tokenized_corpus)\n",
    "output = model.predict(query, len_results=5)\n",
    "\n",
    "etime = time.time()\n",
    "logging.info('Total time {} seconds'.format(etime - stime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[' Preferred Stock, Series A Preferred Stock  or Series A-1 Preferred Stock  (as applicable) that have',\n ' Seed Preferred Stock, Series A Preferred  Stock or Series A-1 Preferred Stock  (as applicable) into',\n ' Preferred Stock, $1.3049  per share forholders of Series A Preferred Stock and $2.3199 for',\n 'series of Preferred Stock;',\n ' such Preferred Stock']"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597779797356",
   "display_name": "Python 3.7.3 64-bit ('3.7.3': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}